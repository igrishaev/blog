---
layout: post
title: "Не люблю регулярки"
permalink: /no-regex/
tags: programming regex
---

Признаться, я не особо люблю регулярные выражения. Я знаю их где-то на троечку,
время от времени применяю, но стараюсь, чтобы их было меньше.

Дело в том, что регулярные выражения — это сверхплотный, сверхкраткий язык
описания шаблонов в тексте. Из его главного преимущества — краткости — следует
главный недостаток. Когда регулярка больше какого-то порога, ее понимание и
поддержка резко идут вниз. В этом случае следует отказаться от регулярки, однако
в проекте запросто может оказаться маньяк, который накрутит еще пару этажей
регулярок.

Другой момент — с регуляркой часто оказывается, что ты не все учел. Предположим,
нужно искать в тексте числа с плавающей запятой. Вы написали регулярку, которая
ищет числа вроде `-12.0042`. А потом оказалось, что у чисел может не быть целой
части, например `-.0042`. А еще оказались числа в научной нотации: `-1.2E9`. И
регулярку нужно допиливать, допиливать и накидывать тесты.

У регулярок есть хорошее применение: ими удобно разбивать текст. Как правило, я
разбиваю текст на части и проверяю, что их количество и содержимое чему-то
соответствует. Это проще отлаживать, это лучше в плане сообщения об ошибке. Если
текст не натягивается на монструозную регулярку, ты не можешь объяснить, что
пошло не так. А если обрабатывать текст по частям, легко сказать, в чем
проблема.

В одном из проектов у нас была библиотека для генерации регулярок. Это когда
декларативно указываешь: либо это слово, либо это, либо то, но не это и не то, и
библиотека строит одну регулярку. В ней учитываются общие начала слов, например
для `fuck` и `fuckoff` получим `fuck(?=off)`. Выбрал такой пример, потому что
фильтровали сообщения в чате. Было много других слов, значения которых я не знал
и смотрел в словаре.

Этот подход интересен тем, что регуляркам отводится служебная
часть. Конфигурация делается словарями и списками, все ясно и прозрачно.

Вместо регулярок мне больше нравится парсинг грамматикой. Пару лет назад я
прочитал пару статей про комбинаторные парсеры и решил сделать свой. В
результате я написал огрызок, который назвал Ostap (потому что великий
комбинатор). В библиотеке были простые парсеры и те, что составляются из других
(and, or). Можно задать грамматику словарем и получить из нее парсер.

[json]: https://github.com/igrishaev/ostap/blob/master/src/ostap/json.clj

В результате у меня получилось составить [грамматику JSON][json], и парсер
разбирал произвольный JSON-документ. Правда, это было медленней джавного Jackson
раз в десять, но за скоростью я не гнался. Почему-то зачесались руки сесть и
переписать его на Джаве и собрать парсеры для JSON, INI, Tolm и других форматов.

Словом, регулярки хороши, но я предпочитаю держать их на расстоянии вытянутой
руки. Чем они ближе, тем строже я слежу за ними.
