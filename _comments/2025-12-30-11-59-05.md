---
comment_id: 1767095944871
is_spam: false
is_deleted: false
post: /why-ai/
date: 2025-12-30 11:59:05 +0000
author_fullname: 'anonymouse'
---

>"Из каждого утюга слышно, что продуктивность увеличилась в разы." 

Слышно от кого? От тех кому проплатили конечные бенефициары за то, чтобы всем и вся распиарить, навязать и подсадить на ML-based технологии и потом эту зависимость эксплуатировать по-полной? 

От всяких начинающих тайпскриптеров, джавистов и питонистов, которым моделька за секунду сгенерила какой-то г***окод для задач, которые уже тысячи раз были решены и описаны?

Мы живём в мире где давным-давно ценности конечных потребителей никого не интересуют, равно как и интересы разработчиков. Что тех что других вынуждают жрать то что дают жрать ради каких-то финансовых игрищ владельцев крупных бизнесов и государств.

>"Говорят: используй AI для новых областей."

Имхо, худший совет с учётом того как создаются и работают нейросетевые модели (на основе каких-то существующих аннотированных датасетов), если имелось ввиду не самообучение чему-то новому с их помощью. Они буквально как раз наоборот наиболее подходят подходят только для генерации того, что уже и так было кучу раз проделано, решено и подробно описано словами людьми много раз.

Как наводка и один из ВСПОМОГАТЕЛЬНЫХ инструментов - оправдано. Как автоматизация чего бы то ни было - нет, нет, нет и ещё раз нет, из-за стохастической неинтерпретируемой природы генерации ML-based моделями выводных данных по вводным. 

Впрочем последнее как мне кажется может ещё хоть как-то работать для языков со статической типизацией, где есть выраженная стандартизация пишущегося кода \ типовых решений и где есть продвинутый анализ кода до рантайма, если через MCP проверится проходит ли код проверку линтером-компилятором.

А нам с Кложей и интерактивной разработкой в REPL-е прямо в рантайме и при динамической типизации банально некуда особо даже прикладывать всякие LLM \ GPT и основанные на них т.н. "агенты". Кроме...

- генерации наводок на что-то, что сам не можешь сходу догадаться как решить, генерации набора каких-то базовых конструкций
- агрегации уже существующего и описанного в сети, чтобы не лазать по кучам сайтов

...при условии выполнения допущения о том, что искомое или нечто схожее вообще существовало в датасете, который использовался при создании используемой модели, т.е. было ли искомое вообще опубликовано и описано людьми в сети или другом массиве данных, использовавшемся при создании модели с помощью ML-алгоритмов.

У нас на языке 0 бойлерплейта и нам даже не надо ничего генерировать. Ты не один кто видит эту всю помешанность на т.н. "AI" как полный bullshit.
