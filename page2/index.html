<!DOCTYPE html>
<html lang="ru">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Ivan Grishaev's blog</title>
  <meta name="description" content="Writing on programming, education, books and negotiations.
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="canonical" href="https://grishaev.me/page2/">
  <link rel="alternate" type="application/rss+xml" title="Ivan Grishaev's blog" href="https://grishaev.me/feed.xml">

  <link rel="shortcut icon" type="image/x-icon" href="/assets/static/favicons/favicon.ico">

  <script type="text/javascript" src="/assets/typo.js"></script>

</head>


  <body>
    <header class="site-header">

    <div class="wrapper flex-container">

        <div>
            <a href="/">
                <img id="avatar" src="/assets/static/avatar.jpg" alt="Ivan Grishaev">
            </a>
        </div>

        <div class="flex-container-vert" style="margin-left: 15px; width: 80%">

            <div class="flex-container full-width">
                <p style="margin-bottom: 5px">Ivan Grishaev's blog</p>
                <div class="flex-huge"></div>
                <div >
<form id="search-form"
      target="_blank"
      style="display: inline"
      method="get"
      action="https://www.google.com/search">

    <input name="sitesearch"
           value="grishaev.me"
           type="hidden">

    <input type="text"
           required="required"
           name="q"
           placeholder="Google search..."
           autocomplete="off">

    <button style="border: none; background-color: transparent; cursor: pointer;"
            type="submit">&#x1f50d;</button>

</form>
</div>
            </div>

            <p><small>Writing on programming, education, books and negotiations.
</small></p>

            <div class="flex-container">
                <a class="menu-item" href="/">Home</a>
                <a class="menu-item" href="/about/">About</a>
                <a class="menu-item" href="/bookshelf/">Bookshelf</a>
                <a class="menu-item" href="/feed.xml">RSS</a>
            </div>

            <div class="flex-container">
                <a class="menu-item minor" href="/tag/clojure/">Clojure</a>
                <a class="menu-item minor" href="/tag/emacs/">Emacs</a>
                <a class="menu-item minor" href="/tag/python/">Python</a>
                <a class="menu-item minor" href="/tag/programming/">Programming</a>
                <a class="menu-item minor" href="/interview/">Interview</a>
                <a class="menu-item minor" href="/video/">Video</a>
            </div>

            <div class="flex-container">
                <a class="menu-item minor hl" href="/clojure-in-prod/">Книга «Clojure на производстве»</a>
            </div>

            <div class="flex-container">
                <a class="menu-item minor hl" href="/clojure-in-prod-2/">Книга «Clojure на производстве», второй том</a>
            </div>

        </div>
    </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="home">

    <ul class="post-list">
        
        <li>

            <h2>
                <a class="post-link" href="/ff-policy/">Firefox и полиси</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/firefox/" rel="tag">firefox</a>, <a href="/tag/policy/" rel="tag">policy</a>, <a href="/tag/updates/" rel="tag">updates</a>

</div>


            <div class="entry">
                
                    <p>На выходных посидел с Firefox. Понял, как заблокировать обновления, а также
много чего другого.</p>

<p>Если коротко: демократия закончилась. Начиная с какой-то версии Firefox перешел
на систему полиси для расширенных настроек. Редактор about:config по-прежнему
работает, но нужно понимать: многие опции теперь — бутафория. Можете до
посинения что-то включать и выключать, эффекта не будет.</p>

<p>Теперь Firefox работает с полиси. Это JSON-файл с директивами, которые включают
ту или иную функцию. По сравнению с about:config преимущество в коллекциях: в
полиси можно задать массив объектов, например, для настройки расширений или
mime-типов, а в <code class="language-plaintext highlighter-rouge">about:config</code> все было плоским.</p>

<p>Полиси описаны в формате JSON, но на Маке используется яблочный формат plist.
Может быть, JSON тоже можно, но я не проверял.</p>

<p>Преимущество полиси в том, что можно задать поведение браузера до последних
мелочей. И все это — в текстовом файле, который хранится в Github. Не нужна
облачная учетка для синхронизации — вы сами решаете, как раскидывать файл по
машинам. Я положил в приватный dotfiles, но приведу копию ниже.</p>

<p>Firefox не пытается оспорить то, что указано в полиси. Если сказано не ставить
обновления — он не ставит. Сказано не проверять браузер по умолчанию — не
проверяет. Никаких попапов, бейджей, нотификаций, алертов, всплывающих полосок и
прочей ахинеи.</p>

<p>Теперь технические шаги. Все примеры будут под мак; на другие системы, думаю,
переложить будет не трудно.</p>

<p>Firefox ищет полиси в разных местах, но самое очевидное — файл <code class="language-plaintext highlighter-rouge">~/Library/
Preferences/org.mozilla.firefox.plist</code>. Опция <code class="language-plaintext highlighter-rouge">EnterprisePoliciesEnabled</code>
означает, использовать ли полиси или пропускать их. Установите ее в истину
командой:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>defaults write ~/Library/Preferences/org.mozilla.firefox EnterprisePoliciesEnabled -bool  TRUE
</code></pre></div></div>

<p>Обратите внимание, что расширение <code class="language-plaintext highlighter-rouge">.plist</code> указывать не нужно.</p>

<p>Чтобы выключить обновления, задайте <code class="language-plaintext highlighter-rouge">DisableAppUpdate</code> в истину:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>defaults write ~/Library/Preferences/org.mozilla.firefox DisableAppUpdate -bool true
</code></pre></div></div>

<p>Перезапустите браузер и откройте About Firefox или настройки — там будет
следующее:</p>

<p><img src="/assets/static/aws/ff-policy/1.jpeg" /></p>

<p><img src="/assets/static/aws/ff-policy/2.jpeg" /></p>

<p>Обновления запрещены, никто не пройдет.</p>

<p>Список полиси можно посмотреть во вкладке <code class="language-plaintext highlighter-rouge">about:policies</code>. Выглядит так:</p>

<p><img src="/assets/static/aws/ff-policy/3.jpeg" /></p>

<p>Назревает два вопроса. Первый: как узнать, какие полиси есть в принципе и их
значения? Второй: ты предлагаешь вводить их в консоли вручную?</p>

<p>Полный список полиси находится <a href="https://mozilla.github.io/policy-templates/">на этой странице</a>, и он довольно
велик. Проще скачать заголовку под вашу систему и поправить руками. Названия
директив говорят сами за себя.</p>

<p>По второму пункту — разумеется, нужно создать файл в редакторе, но в случае с
plist есть нюанс. Файлы plist бывают двух форматов: текстовый и бинарный. В
первом случае это XML с тегами <code class="language-plaintext highlighter-rouge">&lt;plist&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;dict&gt;</code> и <code class="language-plaintext highlighter-rouge">&lt;key&gt;</code>. Во втором случае
там байты вперемешку с текстом.</p>

<p>Беда в том, что Firefox работает только с бинарным plist: если положить
текстовый, он его игнорирует. Бинарник можно поправить в XCode, но это неудобно:
не станете же вы хранить бинарь в Github и редактировать программой, которой
нужно 15 гигов. К счастью, утилита plutil умеет импорт-экспорт, а заодно
проверяет формат на корректность.</p>

<p>У меня получилась папка в dotfiles со следующими файлами. Прежде всего это
org.mozilla.firefox.plist, который я <a href="https://gist.github.com/igrishaev/4e0603f0129a62c335f2f38676059753">выложил в Gist</a>. Вот неполный список
того, что он делает:</p>

<ul>
  <li>отключает обновления</li>
  <li>отключает проверку браузера по умолчанию</li>
  <li>отключает менеджер паролей, мастер-пароль</li>
  <li>отключает Pocket</li>
  <li>убирает партнерские ссылки, top-sites и прочий шлак на главной</li>
  <li>открывает PDF-файлы в Preview.app. Для меня это важно, потому что встроенные</li>
  <li>открывашки PDF, как правило, убогие</li>
  <li>отключает всякий трекинг и фингерпринт</li>
  <li>включает запросы нотификаций, локиции</li>
  <li>блокирует попапы</li>
  <li>отключает “что новенького”, рекомендованные расширения, фичи.</li>
</ul>

<p>Второй файл — конфиг Make, чтобы управлять конфигурацией. Он короткий,
приведу полностью:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DOMAIN = ~/Library/Preferences/org.mozilla.firefox.plist
SOURCE = org.mozilla.firefox.plist

policy-import: policy-check
 defaults import ${DOMAIN} ${SOURCE}

policy-false:
 defaults write ${DOMAIN} EnterprisePoliciesEnabled -bool FALSE

policy-true:
 defaults write ${DOMAIN} EnterprisePoliciesEnabled -bool TRUE

policy-check:
 plutil ${SOURCE}
</code></pre></div></div>

<p>Команда <code class="language-plaintext highlighter-rouge">policy-import</code> переносит настройки из текстового .plist-файла в бинарный в
домашней папке. Она зависит от <code class="language-plaintext highlighter-rouge">policy-check</code>, которая проверяет конфигурацию на
корректность.</p>

<p>Команды <code class="language-plaintext highlighter-rouge">policy-false</code> и <code class="language-plaintext highlighter-rouge">policy-true</code> отключают и включают полиси. Дело в том,
что пока они включены, вы не можете обновиться даже если захотите — функция
запрещена. Чтобы это сделать, отключите полиси, перезапустите браузер,
обновитесь, затем снова включите. На короткое время ужаснитесь тому, как жили
раньше: браузер выплюнет сто попапов, что пора обновиться, сделать его главным
по умолчанию, а вот здесь у нас новая менюшка, а вот новое расширение, ну и все
такое.</p>

<p>В общем, разобраться с полиси было полезно. По аналогии с Емаксом и прочими
утилитами, я храню конфиг в дотфайлах и синхронизирую через Гитхаб. Опасение
вызывает лишь то, что полиси все еще на этапе разработки. Не ровен час,
обновишься — и все слетит.</p>

<p>Вроде бы хороший конец, но все равно — с толикой грусти. Эта борьба вызвана тем,
что некие придурки спрятали опции из интерфейса. Не будь придурков — не было бы
суеты, конфигов и прочего. Энтропия и трение — вот есть то, что здесь описано.</p>

<p>Напоследок — ссылки:</p>

<ul>
  <li><a href="https://mozilla.github.io/policy-templates/">Официальный список полиси</a></li>
  <li><a href="https://github.com/mozilla/policy-templates/blob/master/mac/org.mozilla.firefox.plist">Готовые шаблоны</a></li>
  <li><a href="https://gist.github.com/igrishaev/4e0603f0129a62c335f2f38676059753">Мой конфиг</a></li>
</ul>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/foles-mac-to-win/">Файлы с мака на винду</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/mac/" rel="tag">mac</a>, <a href="/tag/windows/" rel="tag">windows</a>, <a href="/tag/fat32/" rel="tag">fat32</a>

</div>


            <div class="entry">
                
                    <p>Небольшая заметка, чтобы в будущем не искать в интернете.</p>

<p>Предположим, нужно перенести большой файл с мака на виндоуз. Сеть не настроена,
файлы не пошарены, настроить все это займет час. В распоряжении есть флешка
большой емкости, но вот засада:</p>

<ul>
  <li>
    <p>файловая система NTFS на маке работает только для чтения;</p>
  </li>
  <li>
    <p>яблочная файловая система APFS не видна в винде;</p>
  </li>
  <li>
    <p>файловая система FAT32 работает в обоих средах, но не поддерживает файлы
больше двух гигабайт.</p>
  </li>
</ul>

<p>Что же делать? Можно поставить продвинутый архиватор с поддержкой
мульти-архивов. Это когда архив делится на тома foobar.zip.01, 02 и так далее
заданной величины. Но ставить софт очень не хочется.</p>

<p>Оказывается, все утилиты есть в коробке. На маке делаем так:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>split -b 2024m SomeMovie.mkv SomeMovie.mkv.
</code></pre></div></div>

<p>Последний аргумент с точкой — шаблон нарезанных кусков. К ним будут добавлены
строки aa, ab, ac и так далее для правильной сортировки. Если исходный файл был
5 гигабайтов, получатся файлы <code class="language-plaintext highlighter-rouge">SomeMovie.mkv.aa</code>, <code class="language-plaintext highlighter-rouge">SomeMovie.mkv.ab</code> и
<code class="language-plaintext highlighter-rouge">SomeMovie.mkv.ac</code>.</p>

<p>Скидываем все добро на флешку, и теперь с FAT32 не будет проблем, потому что
каждый кусок не превышает два гига. Чтобы собрать файл на винде, запускаем
команду:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>copy /b SomeMovie.mkv.* SomeMovie.mkv
</code></pre></div></div>

<p>Очевидно, это нужно делать не на флешке, а на жестком диске. Можно положить
рядом батник, если собирать будете не вы.</p>

<p>Польза способа в том, что не нужен сторонний софт, права администратора и прочая
ахинея. Просто работает.</p>

<p><strong>UPD</strong>: в комментариях к написли про exFat, а я про него как-то
забыл. Действительно, с ним все работает. Поэтому все, что описано выше,
пригодится, если флешка мала. Например, когда нужно перетащить файл на 16 гигов,
а флешка только два.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/aws-3/">AWS, история третья. Разрывы</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/aws/" rel="tag">aws</a>, <a href="/tag/cloud/" rel="tag">cloud</a>, <a href="/tag/programming/" rel="tag">programming</a>, <a href="/tag/athena/" rel="tag">athena</a>, <a href="/tag/s3/" rel="tag">s3</a>

</div>


            <div class="entry">
                
                    <p>Все статьи из цикла AWS</p>

<ul>
  <li><a href="/aws-0/">Амазон</a></li>
  <li><a href="/aws-1/">AWS, история первая. Внезапный мегабайт</a></li>
  <li><a href="/aws-2/">AWS, история вторая. Афина прекрасная</a></li>
  <li><a href="/aws-3/">AWS, история третья. Разрывы</a></li>
</ul>

<p>В третьей истории расскажу, как я страдал от сетевых проблем в Амазоне. Как
абонент Уральский: раньше не было разрывов, а теперь есть разрывы.</p>

<p>У нас в проекте много лямбд, и каждая вызывает другие. При таком раскладе
невыгодно передавать результат напрямую. Можно использовать S3 как шину
данных. Например, одна лямбда вызывает другую и говорит: положи результат в
такой-то бакет и файл. Затем опрашивает файл, пока он не появится.</p>

<p>Это удобно, когда результат огромен: иные лямбды производят CSV-шки по нескольку
гигабайт. Не гонять же их напрямую между лямбдами. Но файлы привносят хаос: не
всегда очевидно, кто произвел файл и кто его потребители. Если изменить путь,
через день придет коллега из другого сервиса и скажет: мы каждый день забираем
файл из этой папки, куда он делся? Или наоборот: ты обнаружил, что некий сервис
производит удобный файл, в котором все есть. Через месяц он перестал появляться,
потому что они переехали на что-то другое. Мы вам ничего не обещали.</p>

<p>Файлы CSV удобно стримить прямо из S3. Послал GET-запрос, получил InputStream.
Передал его в парсер и готово: получается ленивая коллекция кортежей. Навесил на
нее map/filter, все обработалось как нужно, красота. Не нужно сохранять файл на
диск.</p>

<p>То же самое с форматом JSONL, где каждая строка — отдельный объект JSON. Из
стрима получаешь Reader, из него ленивый line-seq, и пошел колбасить.</p>

<p>Неожиданно это схема перестала работать с большими файлами. Где-то на середине
цикл обрывается с IOException. Чего я только не пробовал: оборачивал стрим в
BufferedInputStream с разным размером, засекал время обработки, передавал опции
в к S3… ничего не помогло. Запросы в Гугл тоже ничего внятного выдали.</p>

<p>У меня подозрение, что дело в неравномерном чтении. Когда вы читаете файл,
Амазон определяет скорость забора байтиков. Поскольку мы читаем и обрабатываем
стрим в одном потоке, чтение чередуется с простоем на обработку данных. В
больших файлах я нашел записи, которые больше других во много раз.  Возможно,
что когда обработка доходила до них, ожидание было больше среднего, и Амазон
закрывал соединение.</p>

<p>Я пытался повторить это на публичных файлах S3: читал в цикле N байтов и где-то
на середине ставил длинный Thread/sleep. Но S3 покорно ждал аж две минуты, и
эксперимент провалился.</p>

<p>Словом, я так и не выяснил, почему вылазит IOException, но смог это исправить в
два шага.</p>

<p>Первый — файл S3 тупо записывается во временный файл, и дальше с ним работаешь
локально. Перенос стрима делается одним методом <code class="language-plaintext highlighter-rouge">InputStream.transferTo</code>. Во
время переноса ошибки связи не возникают.</p>

<p>Второй — иные агрегаты достигают 3.5 гигабайтов, а у лямбды ограничение на 10
гигабайтов места. Скачал три агрегата — и привет, out of disk space. Поэтому при
записи файл кодируется Gzip-ом, а при чтении — декодируется обратно.</p>

<p>Все вместе дало мне функцию, которая:</p>

<ul>
  <li>посылает запрос к S3, получает стрим</li>
  <li>создает временный файл</li>
  <li>переносит стрим в файл, попутно сжимая Gzip-ом</li>
  <li>возвращает <code class="language-plaintext highlighter-rouge">GzipInputStream</code> из файла</li>
</ul>

<p>Со стороны кажется, что вызвал <code class="language-plaintext highlighter-rouge">get-s3-reader</code> — и байтики потекли, делов-то. А
внутри вот какие штучки.</p>

<p>Примечательно, что в одном проекте я сам спровоцировал
<code class="language-plaintext highlighter-rouge">IOException</code>. Разработчик до меня позаботился о переносе файла S3 во временный
файл. Я подумал, что он просто не знает, как обработать данные из сети и убрал
запись на диск. Возможно, он что-то знал, но не оставил комментария. А надо
было!</p>

<p>Из этой истории следует: никогда не обрабатывайте файл S3 сразу из сети.
Сохраните его во временный файл и потом читайте локально — так надежней. Рано
или поздно вы схватите <code class="language-plaintext highlighter-rouge">IOException</code>, а на расследование будет времени. Чтобы
сэкономить диск, оберните файл в Gzip.</p>

<hr />

<p>На этом я закончу истории про Амазон. У меня есть еще несколько, но они не такие
интересные и сводятся к тезису “думал так, а оно эдак”. Ну и обсасывать одну и
ту же тему уже не хочется.</p>

<p>Думаю, вы поняли, что в Амазоне хватает странностей. Это не баги, потому что все
они описаны в документации. Примерно как в Javascript: никто не знает, почему
<code class="language-plaintext highlighter-rouge">{} + [] = 0</code>, а <code class="language-plaintext highlighter-rouge">[] + {} = [object Object]</code>. Да, в стандарте описано, но кому
от этого легче?  Выбирая Амазон, закладывайте время и деньги на подобные
непонятки.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/aws-2/">AWS, история вторая. Афина прекрасная</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/aws/" rel="tag">aws</a>, <a href="/tag/cloud/" rel="tag">cloud</a>, <a href="/tag/programming/" rel="tag">programming</a>, <a href="/tag/athena/" rel="tag">athena</a>, <a href="/tag/s3/" rel="tag">s3</a>

</div>


            <div class="entry">
                
                    <p>Все статьи из цикла AWS</p>

<ul>
  <li><a href="/aws-0/">Амазон</a></li>
  <li><a href="/aws-1/">AWS, история первая. Внезапный мегабайт</a></li>
  <li><a href="/aws-2/">AWS, история вторая. Афина прекрасная</a></li>
  <li><a href="/aws-3/">AWS, история третья. Разрывы</a></li>
</ul>

<p>Расскажу о еще одном случае с AWS, который стоил мне пару бессонных ночей.</p>

<p>В Амазоне есть славный сервис Athena — супер-пупер агрегатор всего и вся. Он
тащит терабайты данных из разных источников, обрабатывает и складывает в другие
сервисы. Хадуп на стероидах. По-русски читается “Афина”.</p>

<p>Мы пользуемся им так. Есть лямбда, которая складывает в S3 сущности в JSON.
Сущностей более миллиона. Другим сервисам нужны все сущности разом — и
оказывается, выгрести их из S3 невозможно.</p>

<p>Почему? Даже если предположить, что за секунду мы скачаем 10 сущностей
параллельно (что невозможно), за 900 секунд мы получим 9000 сущностей, что
меньше одного процента. А нам нужно не девять тысяч, а миллион. Напомню, что 900
секунд — это 15 минут, максимальное время работы лямбды.</p>

<p>Архитектуру дизайнил не я, поэтому не спрашивайте, почему так.</p>

<p>На помощь приходит Афина. Мы говорим ей: склей все JSON файлы из бакета в один и
положи туда-то. Афине, при всей мощи Амазона, нужно на это 4 минуты.  Чудес не
бывает, и чтобы забрать из S3 миллион файлов, Амазону нужно попотеть.</p>

<p>В ответ на нашу просьбу Афина дает айдишник задания, и мы его поллим. Готово?
Нет. Готово? Нет. Готово? Да. И если да, в ответе будет ссылка на файл-агрегат.</p>

<p>Таких агрегатов у нас несколько, и я столкнулся с тем, что лямбда не
укладывается в 15 минут. Если тратить по 4 минуты на агрегат, то на ожидание
трёх уйдёт 12 минут.  Процессинг файлов занимает еще 5-6 минут, и готово — ты не
успел.</p>

<p>Тратить 12 минут впустую глупо, поэтому я сделал поллинг Афины параллельным. В
самом деле, зачем ждать 4 минуты, если можно запустить второй поллинг? Логично
же? Но вот к чему это привело.</p>

<p>Кто-то заметил, что в отчетах стали появляться “дырки”, то есть пустые ячейки. С
точки зрения кода это выглядит так, словно в агрегате не было записей. Сначала я
отнеткивался, но потом проверил размеры агрегатов. Оказалось, что сегодняшний
файл, собранный Афиной, в два раза меньше вчерашнего. Или наоборот: вчера ок, а
сегодня половина. Файл не битый, открывается, просто в нем половина данных.</p>

<p>После гуглений, осбуждений и вырванных волос обнаружились сразу три бага.</p>

<p>Первый — разработчик, который писал код до меня, допустил ошибку. Он поллил
Афину по условию “пока статус pending”. Если что-то другое, он читал результат.
Оказалось, что у задачи может быть три статуса: pending, ready и error. И в
нашем случае статус был error.</p>

<p>Второй — даже если задача в статусе error, она содержит ссылку на собранный
файл. Да, Афина не смогла, и файл собран частично. Считается, что это лучше, чем
ничего.</p>

<p>Третий — в чем была причина error? Напомню, что я запускал в Афине несколько
задач параллельно. Каждая задача собирала файлы из S3. В итоге сработал лимит на
доступ к S3 — он ответил, что кто-то слишком часто обращается ко мне, убавьте
пыл, господа. Поэтому задача упала.</p>

<p>Интересно, что S3 не волнует, что обращается к нему не сторонний потребитель, а
сама Афина. При всем абсурде я считаю это правильным, потому что если лимит
задан, он должен соблюдаться глобально, без поблажек “для своих”.</p>

<p>В итоге я сделал следующее. Все отчеты, которые обращаются к Афине, я разнес по
времени с разницей в 5-10 минут. Раньше они стартовали одновременно, что
порождало много задач в Афину, а та насиловала S3. С разницей по времени стало
легче.</p>

<p>Потом я додумался до решения лучше. Сделал фейковый warmup-отчет, который
работает как прогрев кеша. Он запускается первым и триггерит все задачи в Афине.
Когда другим отчетам что-то нужно из Афины, они проверяют, была ли задача с
такими параметрами за последние 2 часа. Если да, ссылка на агрегат берется из
старой задачи.</p>

<p>Вот такая она, борьба с AWS. Перечитываю и понимаю, что, хоть и звучит умно,
хвастаться здесь нечем. Не будь этой архитектуры, результат обошелся бы дешевле.
Усилия потрачены, но неясно зачем.</p>

<p>Я пишу комментарии к коду, надеясь, что следующий разработчик поймет хоть толику
все этой котовасии. Но не особо на это надеюсь: скорее всего, он скажет — что
это наговнокодили такое? Пойду переделаю. И все повторится.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/aws-1/">AWS, история первая. Внезапный мегабайт</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/aws/" rel="tag">aws</a>, <a href="/tag/cloud/" rel="tag">cloud</a>, <a href="/tag/programming/" rel="tag">programming</a>, <a href="/tag/s3/" rel="tag">s3</a>

</div>


            <div class="entry">
                
                    <p>Все статьи из цикла AWS</p>

<ul>
  <li><a href="/aws-0/">Амазон</a></li>
  <li><a href="/aws-1/">AWS, история первая. Внезапный мегабайт</a></li>
  <li><a href="/aws-2/">AWS, история вторая. Афина прекрасная</a></li>
  <li><a href="/aws-3/">AWS, история третья. Разрывы</a></li>
</ul>

<p><a href="/aws-0/">Прошлая заметка</a> про AWS была затравкой. Теперь расскажу о случаях в
Амазоне, от которых трещали мозги.</p>

<p>Первая история касается сервиса Lambda. Он выполняет произвольный код на
любом языке и возвращает результат. Особенность Лямбды в том, что клиент
платит только за те ресурсы, что потребил. Считаются время процессора, память и
диск в секунду. Если не вызывать Лямбду, ее стоимость будет нулевой.</p>

<p>Это выгодно отличает Лямбду от EC2, за который клиент платит всегда. Наверное,
все видели мемы про бомжа, который скатился в бедность, не выключив инстанс
EC2.</p>

<p>Кто-то считает, что Лямбда — простой сервис, но это не так. Наоборот, он один из
самых сложных в AWS. Он работает как огромная очередь задач. Лямбду можно
скрестить с HTTP-сервером, чтобы принимать сообщения прямо из браузера. Лямбду
можно прицепить к любому сервису AWS в качестве реакции на что угодно.
Загрузили файл в S3 — вызвалась лямбда. Отправили сообщеньку в очередь —
вызвалась лямбда и так далее.</p>

<p>Я работаю в проекте, в котором все на лямбдах. Раньше мне казалось это
фантасмагорией, но со временем привыкаешь. В порядке вещей, когда лямбда дергает
лямбду, которая дергает лямбду, которая дергает лямбду. Постепенно видишь в этом
особый шарм.</p>

<p>У лямбды жесткие лимиты, которые нельзя нарушать. Время работы не может быть
дольше 15 минут. Если его превысить, лямбда умирает и запускается опять.
Максимальное число повторов — 4. Ответ не может быть больше 6 мегабайтов. В теле
может быть только текст, бинарные данные запрещены.</p>

<p>Про размер тела я и хотел рассказать.</p>

<p>Одна из лямбд распухла и стала отдавать JSON, который не пролазил в 6
мегабайтов. Это нетрудно поправить. Нужно сжать тело Gzip-ом и обернуть в
base64. Зачем? Как я сказал, в теле не может быть бинарь, потому что данные
передаются в JSON. Такой вот костылик, но что поделаешь.</p>

<p>Не обошлось без приключений: клиенты лямбды использовали кривую библиотеку,
которая не учитывала сжатие Gzip. Пришлось починить ее тоже: проверять Content-
Encoding и оборачивать стрим, если там gzip. В общем, кое-как все подружились, и
сообщения пошли как надо.  Как-то раз я задался вопросом: какого размера был тот
ответ, что не влез в лимит?</p>

<p>Добавил лог с размером JSON до сжатия. Оказалось, он был 5.2 мегабайта.</p>

<p>Может быть, не всем понятно это противоречие, но я впал в ступор. Сказано ясно:
тело не больше 6 мегабайтов, а у нас 5. Почему сообщение не проходит? Откуда
лишний мегабайт?  Это страшно взволновало меня: происходит какая-то фигня, о
которой я не догадываюсь.</p>

<p>Я полез в интернет и выяснил, что какой-то бедняга уже наступал на эти
грабли. На <a href="https://stackoverflow.com/questions/66971400/aws-lambda-body-size-is-too-large-error-but-body-size-is-under-limit">StackOverflow</a> нашелся вопрос, и автор долго искал ответа. Он
даже писал сводки с апдейтами! Были разные предположения, в том числе такие, что
AWS дописывает мету в сообщения. Но не мегабайт же! Они что, Анну Каренину в
заголовках передают?</p>

<p>На сегодняшний день у вопроса 21 тысяча просмотров и ни одного верного ответа
(за исключением моего). Этот вопрос был скопирован в сервис <a href="https://repost.aws/questions/QU57r4NMQIQROXqW4Vl6YDBQ/">Repost.AWS</a>
— базу знаний AWS, и там тоже ничего не сказали по делу. Это доказывает: в
Амазоне бывает нечто, что никто не может объяснить.</p>

<p>Мысль о лишнем мегабайте не отпускала меня. И вот однажды, прогуливаясь, я все
понял.</p>

<p>Когда лямбда отдает HTTP-сообщение, она строит примерно такой ответ. В его теле
— строка JSON с данными:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>return HTTPResponse(
    200,
    body=json.encode(data),
    content_type="application/json"
)
</code></pre></div></div>

<p>На этом работа программы кончается. А что происходит с ответом? Он
перестраивается в такой словарик:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{:statusCode 200,
 :body &lt;JSON-string&gt;,
 :headers {"content-type" "application/json"}}
</code></pre></div></div>

<p>Потом словарик кодируется в JSON и отправляется в дебри AWS, которые называются
Lambda Runtime API. Это очередь, которая отвечает за прием и отдачу
сообщений. Ваша лямбда — клиент, который забирает оттуда сообщеньки и рапортует
об исполнении. Примерно как Consumer в Кафке.</p>

<p>Теперь про этот мегабайт. Напомню, что до кодирования наш словарик выглядел так
(кложурный синтаксис):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{:statusCode 200,
 :body "{\"foo\":{\"bar\":[\"a\",\"b\",\"c\"]}}",
 :headers {"Content-Type" "application/json"}}
</code></pre></div></div>

<p>Далее он кодируется в JSON. А в поле <code class="language-plaintext highlighter-rouge">:body</code> уже закодированный JSON! Получается
двойное кодирование: данные перегнали в JSON первый раз, чтобы получить
текстовое поле body, а потом еще раз, чтобы закодировать верхний словарь!  При
кодировании JSON происходит экранирование некоторых символов. Например, если в
строке двойная кавычка, перед ней будет обратный слэш. Покажу это на примере:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(pg.json/write-string "aaa \" bbb")
"\"aaa \\\" bbb\""
</code></pre></div></div>

<p>Интересно, сколько же будет этих слэшей? Примерно x2 от числа ключей в словарях
и строк в значениях. Например, если в словаре два ключа и в значениях строки, то
слэшей получится 8. Легко посчитать отношение длины JSON с одним и двойным
кодированием. Оно получится примерно 1.4:</p>

<div class="language-clojure highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="no">:foo</span><span class="w"> </span><span class="p">{</span><span class="no">:bar</span><span class="w"> </span><span class="p">[</span><span class="no">:a</span><span class="w"> </span><span class="no">:b</span><span class="w"> </span><span class="no">:c</span><span class="p">]}}</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w">
    </span><span class="nb">count</span><span class="p">)</span><span class="w">
</span><span class="mi">29</span><span class="w">

</span><span class="p">(</span><span class="nb">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="no">:foo</span><span class="w"> </span><span class="p">{</span><span class="no">:bar</span><span class="w"> </span><span class="p">[</span><span class="no">:a</span><span class="w"> </span><span class="no">:b</span><span class="w"> </span><span class="no">:c</span><span class="p">]}}</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w"> </span><span class="nb">count</span><span class="p">)</span><span class="w">
</span><span class="mi">41</span><span class="w">

</span><span class="p">(</span><span class="nb">/</span><span class="w"> </span><span class="mf">41.0</span><span class="w"> </span><span class="mi">29</span><span class="p">)</span><span class="w">
</span><span class="mf">1.4137931034482758</span><span class="w">

</span></code></pre></div></div>

<p>Проверим это на больших файлах. В интернете нашелся большой публичный JSON. Вот
цифры для него:</p>

<div class="language-clojure highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">-&gt;</span><span class="w"> </span><span class="s">"https://github.com/seductiveapps/largeJSON/raw/master/100mb.json"</span><span class="w">
    </span><span class="n">java.net.URL.</span><span class="w">
    </span><span class="nb">slurp</span><span class="w">
    </span><span class="n">pg.json/read-string</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w">
    </span><span class="nb">count</span><span class="p">)</span><span class="w">
</span><span class="mi">60129867</span><span class="w">

</span><span class="p">(</span><span class="nb">-&gt;</span><span class="w"> </span><span class="s">"https://github.com/seductiveapps/largeJSON/raw/master/100mb.json"</span><span class="w">
    </span><span class="n">java.net.URL.</span><span class="w">
    </span><span class="nb">slurp</span><span class="w">
    </span><span class="n">pg.json/read-string</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w">
    </span><span class="n">pg.json/write-string</span><span class="w">
    </span><span class="nb">count</span><span class="p">)</span><span class="w">

</span><span class="mi">70361681</span><span class="w">
</span><span class="p">(</span><span class="nb">/</span><span class="w"> </span><span class="mf">70361681.0</span><span class="w"> </span><span class="mi">60129867</span><span class="p">)</span><span class="w">

</span><span class="mf">1.170161926351841</span><span class="w">
</span></code></pre></div></div>

<p>Коэффициент вышел 1.17, а размер вырос аж на 10 мегабайтов.</p>

<p><strong>Резюмируя:</strong> двойное JSON-кодирование прибавляет от 5 до 17% к длине строки.
Прибавка состоит из обратных слэшей из-за экранирования кавычек. В моем случае
было примерно 800 Кб слешей. 5.3 + 0.8 = 6.1 мегабайтов. Все сходится.
Напоминает шутку про украденный код на Lisp, где были одни закрывающие скобки.
Тут то же самое, только слэши.</p>

<p>Вот такая штука. Когда все шаги пройдены, она не кажется загадкой, но как же
напрягала тогда! Ее нельзя назвать багом, потому что документация не врет: шесть
мегабайтов. Но дело в том, что эти шесть мегабайтов касаются финального
сообщения, которое уходит в Runtime API. Это не длина данных, что возвращает ваш
код, вот в чем дело. И конечно, документация ничего не знает о двойном
кодировании и проблеме слэшей.</p>

<p><strong>Важно понять:</strong> если вы отдаете HTTP-сообщеньки из Лямбды, и в теле JSON, вы
кодируете его <strong>дважды</strong>. Это добавляет 5-17% процентов от исходной длины. Лучше
сразу использовать Gzip+base64, чтобы не выстрелить в ногу.</p>

<p>Итак, с лямбдой разобрались. В следующей заметке будет кулстори про AWS Athena
(читается “Афина”). Там тоже трещали мозги.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/aws-0/">Амазон</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/aws/" rel="tag">aws</a>, <a href="/tag/cloud/" rel="tag">cloud</a>, <a href="/tag/programming/" rel="tag">programming</a>

</div>


            <div class="entry">
                
                    <p>Все статьи из цикла AWS</p>

<ul>
  <li><a href="/aws-0/">Амазон</a></li>
  <li><a href="/aws-1/">AWS, история первая. Внезапный мегабайт</a></li>
  <li><a href="/aws-2/">AWS, история вторая. Афина прекрасная</a></li>
  <li><a href="/aws-3/">AWS, история третья. Разрывы</a></li>
</ul>

<p>Последние три года я плотно работают с Амазоном. Все больше утверждаюсь в мысли:
для своих нужд я никогда не возьму Амазон, какими бы пряниками он меня не
заманивал.</p>

<p>Двадцать лет назад, когда я только познакомился с AWS, он был набором
сервисов. Если тогда это был город, то сегодня он — целая планета. Число
сервисов выросло на порядок или два, усложнилось взаимодействие между ними.</p>

<p>Разрабатывая на AWS, важно иметь особый навык — знание AWS. Языка
программирования и базы данных уже недостаточно. Нужно понимать концепции AWS,
систему прав и полиси, квоты и много чего другого.</p>

<p>В фирме редко бывает человек, который знает AWS целиком. Чаще всего каждый, как
муравей, видит маленький ландшафтик, и когда начинаются проблемы взаимодействия,
их тяжело расследовать.</p>

<p>AWS — это дичайший вендор-лок, то есть зависимость от поставщика. Байки на тему
“посидим и слезем” остаются байками. Амазон, как пылесос, со временем
перетягивает на себя все решения — файлы, базу, сообщения — и портировать их
обратно очень дорого.</p>

<p>Важно понимать, что второго Амазона в мире нет. Бывают сервисы, которые
повторяют некоторые API Амазона, например S3. Но переехать на что-то другое
целиком будет очень затратно, причем даже не в плане денег, а нервов.</p>

<p>Амазон дорогой. Разумеется, я не могу назвать, сколько платят заказчики, но это
весьма дорого даже по западным меркам. Реляционные базы данных —
дорогие. Лямбды, если их вызывать постоянно — дорогие. Если использовать S3 как
шину данных между сервисами, это тоже дорого.</p>

<p>Пожалуй, моя главная претензия к AWS — его трудно имитировать локально. Когда у
вас Постгрес и Редис, все это запускается в Докере и покрывает 99%
случаев. Постгрес в Докере — это настоящий Постгрес, тот самый, что работает на
серверах. Любую ситуацию можно повторить локально: блокировку транзакций,
медленный запрос, загрузку миллиарда записей, попадание в индекс.</p>

<p>С Амазоном так не получится: сервисы DynamoDB, SNS/SQS или Athena нельзя
запустить в Докере. Можно заткнуть их имитацией, которая выплевывает нужный
JSON, но… это имитация. В проде случается масса вещей, о которых вы и не
подозревали.</p>

<p>Для разработки под Амазон нужно dev-окружение. Это такой же Амазон, только он не
пересекается с продом. Там своя база, инстансы, очереди задач. Вы пишете код,
заливаете в Амазон, гоняете и смотрите логи. Что-то упало — исправляете код и
все по-новой. Это долго, потому что каждый шаг выполняется не мгновенно, а по
нескольку минут.</p>

<p>Разумеется, dev-окружение тарифицируется как обычное. За все нужно
платить. Кроме прода, заказчик платит за 5-10 dev-окружений. Если вы
расчитываете стоимость AWS, умножайте хотя бы на два, чтобы заложить бюджет на
dev-окружения.</p>

<p>Амазон радует крайне неочевидным поведением. Не могу назвать его багами, потому
что оно описано в докуменации. Но документация огромна, читать ее никогда, да и
требует усилий. Каждый раз, разобравшись, думаешь: ну все, теперь сюрпризов не
будет. И буквально через два дня — новая головоломка.</p>

<p>В следующих заметках я расскажу о случаях с AWS, над которыми изрядно поломал
голову. Надеюсь, они будут кому-то полезны и сэкономят нервы.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/avito-2/">Авито (2)</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/avito/" rel="tag">avito</a>, <a href="/tag/ui/" rel="tag">ui</a>, <a href="/tag/idiots/" rel="tag">idiots</a>

</div>


            <div class="entry">
                
                    <p><img src="/assets/static/aws/avito/2.jpeg" /></p>

<p>Уж простите за спам про Авито, но я не могу, правда. Это какой-то лол.</p>

<p>Продавец выставил серию книг, и я спрашиваю, есть ли среди них такая. Что делает
бот Авито? Он выплевывает 7 сообщений о том, что:</p>

<ul>
  <li>можно купить с доставкой</li>
  <li>сроки отправки</li>
  <li>сколько занимает проверка товара</li>
  <li>рейтинг продавца</li>
  <li>куда нажать, чтобы купить</li>
</ul>

<p>И остальное, что не влезло на скриншот, хотя информация есть на странице, и я ее
прекрасно вижу. Самую мелочь — есть ли книга или нет — я так и не узнал.</p>

<p>Как же все это душит. Казалось бы, пройдя все авторизации и преграды, можно
спросить человека и получить живой ответ.  Но Авито не оставляет шансов: и здесь
поджидает бот, который засрет переписку бессмыслицей. И не только Авито,
конечно.</p>

<p>Все это нежно, мягко, с заботой, но поддушивает.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/avito-1/">Авито (1)</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/avito/" rel="tag">avito</a>, <a href="/tag/ui/" rel="tag">ui</a>, <a href="/tag/idiots/" rel="tag">idiots</a>

</div>


            <div class="entry">
                
                    <p><img src="/assets/static/aws/avito/1.jpg" /></p>

<p>Не знаю, что курят в Авито, но система допускает два профиля с одинаковой
почтой, и я должен выбрать один из них. Может, это из-за разных клиентов:
десктоп и телефон? Или из кеша пришли левые данные? Это неважно: техническое
объяснение всегда найдется. Но так быть не должно.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/auth-offends/">Авторизация оскорбляет</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/auth/" rel="tag">auth</a>, <a href="/tag/web/" rel="tag">web</a>, <a href="/tag/services/" rel="tag">services</a>

</div>


            <div class="entry">
                
                    <p>Раньше двойная авторизация работала так: ставишь приложение на телефон,
сканируешь QR-код и получаешь генерилку кодов. Сайт запрашивает код, ты вводишь,
все довольны.</p>

<p>Теперь сервисы отходят от это схемы. Даже если ты включил двойную авторизацию,
сайт предложит зайти в другое приложение той же фирмы. Например, чтобы зайти в
Гмейл, открой Ютуб. Или открой наше мобильное приложение (Гитхаб,
Яндекс). Вариант с кодом прячут под выпадашку “другие способы”.</p>

<p>Меня оскорбляет такой подход. Я заморачивался, ставил эти коды и считаю их
безопасней, чем вход в другое приложение. Тем не менее, сервис понизил приоритет
у кодов и предлагает способ для домохозяек. Не надо так.</p>

                
            </div>

        </li>
        
        <li>

            <h2>
                <a class="post-link" href="/ai-review/">ИИ-ревью</a>
            </h2>

            
<div class="post-meta">

    <time class="post-time"
          datetime="2024-03-10T00:00:00+00:00">
        Mar 10, 2024
    </time>

    <a href="/tag/ai/" rel="tag">ai</a>, <a href="/tag/review/" rel="tag">review</a>, <a href="/tag/work/" rel="tag">work</a>

</div>


            <div class="entry">
                
                    <p>Верьте аль не верьте, но в одном проекте у нас было ИИ-ревью. Слушайте.</p>

<p>Фирма назначила нового технического директора. Уже первый разговор с ним посеял
тревогу. Его технический стек не имел отношения к тому, что был у нас. Он сходу
предложил перейти на MongoDB — оставив за кадром факт, что переезд с гигантской
базы Постгреса занял бы несколько лет. Он много говорил о Chat GPT и о том, как
ИИ-ревью изменит наши процессы.</p>

<p>Начальство дало добро, и техдир провел три месяца, настраивая ИИ-ревью. Если
вкратце, оно работало так.</p>

<p>Нашелся бот на Node.js, который парсит дифф и выдирает изменения. Бот крутится в
CI и запускается на каждом коммите.</p>

<p>Выдрав изменения и собрав контекст, бот отправлял все добро в Chat GPT и
составлял отчет.</p>

<p>Этот отчет добавлялся в комментарий к пулл-реквесту.</p>

<p>Звучит круто, а что было на самом деле? Это выглядело так. По каждому файлу бот
писал: добавлена такая-то функция, переименован такой-то параметр, функция
foo-bar теперь принимает три аргумента, а не два. И все таком духе:
человекоподобное описание изменений. Ниже он писал вердикт — хороши ли изменения
или требуют доработки.</p>

<p>Постарайтесь это представить: в пул-реквесте пятнадцать файлов, и по каждому бот
пишет абзац текста. Получается портянка на два экрана, совершенно тупая и
бесполезная. Что с того, что написано “добавлена новая функция”? Я из без бота
вижу, что она добавлена. Вполне может быть, что похожая функция уже есть, либо
это могло быть inline-выражение, либо есть лучшая версия этой функции в
библиотеке? Бот ничего об этом не знал.</p>

<p>Открывая PR, ты первым делом видел выхлоп ИИ на два экрана. Нужно было
проматывать эту фигню, чтобы добраться до кода.</p>

<p>Получилась своего рода версия PR для менеджеров. Ну, знаете, бывает версия для
слабовидящих, а есть версия для менеджеров. Менеджер не может прочесть код, и
система генерит ему описание: добавилось то, убавилось это. Читая выхлоп,
менеджер думает, что понимает код, хотя это не так. Он понимает действие, но не
понимает причины, не понимает смысла, который стоит за этим кодом.</p>

<p>Чтобы портянка на два экрана не мешала, я стал удалять ее из PR. В том числе не
только из своих PR, но и коллег, если меня просили сделать ревью. Открывая PR, я
рассчитываю увидеть код, а не машинный выхлоп, пусть даже его произвел ИИ. И
знаете, никто не жаловался на удаление. Скоро я заметил, что коллеги молча
удаляют этот комментарий без моего вмешательства.</p>

<p>Стоит ли говорить, что бот ничего не знал о безопасности и хороших практиках. Он
спокойно пропускал места, где SQL-параметр подставлялся склейкой строк. Он
ничего не знал о reflection warning, о кривых запросах, неэффективных циклах,
запросах мимо индекса.</p>

<p>Удивлял его вердикт: бот мог написать “все отлично” к файлу, к которому у меня
было три претензии. Мог написать “требует доработки” к файлу, где все
гладко. Само собой, без каких-либо объяснений, что именно требует доработок и
каких.</p>

<p>Получался молчаливый бойкот: разработчики не обращали внимания на бота, техдир
ничего в Кложе не понимал, а бот не давал ответа на вопрос, хороший мы пишем код
или нет.</p>

<p>Добавлю, что еще раньше техдир хотел подключить в CI сторонний говносервис,
который делает то же самое. К счастью, в списке поддерживаемых языков не было
Кложи.</p>

<p>И вот однажды бота отключили. Я не стал спрашивать о причинах: они были
очевидны. ИИ-ревью не оправдало себя, а директор потратил три месяца на его
настройку. Ничего не изменилось в лучшую сторону, стало только хуже, потому что
добавился новый компонент, усложнился CI, были потрачены деньги. Позже директора
уволили.</p>

<p>В чем была его ошибка? В том, что он не мог четко объяснить, какую проблему он
решал с помощью ИИ. Я уже писал про это: принимаясь за задачу, спрашивай себя,
какую проблему ты решаешь. В том проекте у нас было хорошее ревью: никто не
затягивал процесс, сложные диффы смотрели несколько человек. В команде была
компетенция в плане Кложи и SQL. Словом, ревью было последним местом, куда бы я
внедрил ИИ.</p>

<p>Вот что бывает, когда за дело берутся менеджеры. Их стремление автоматизировать
понятно: вдруг человек уйдет, а мы такие внедрили ИИ, и ладушки: он с нами
навсегда. Увы, это не работает: есть процессы, которые должен выполнять
человек. Всякие ИИ могут быть страховкой, но не более того.</p>

                
            </div>

        </li>
        
    </ul>

    <h4>
        
        <a href="/" class="previous">&larr;</a>
        
        <span class="page_number ">Страница 2 из 73</span>
        
        <a href="/page3" class="next">&rarr;</a>
        
    </h4>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Ivan Grishaev's blog</li>
          <li><a href="mailto:ivan@grishaev.me">ivan@grishaev.me</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
            <li><a href="https://github.com/igrishaev">GitHub</a></li>
            <li><a href="tg://resolve?domain=igrishaev_blog">Telegram</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Writing on programming, education, books and negotiations.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
